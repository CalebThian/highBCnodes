{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbf6a13",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb22d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import kendalltau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206514a0",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing  \n",
    "Data Structure:\n",
    "1. **gList** <Dict>: containing total 31 graphs, which 30 from Synthetic and 1 from youtube,using filename as key  \n",
    "2. element of gList <Dict>: 'graph':nx.Graph();'score': <Dict> with 'node' and 'score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4b0a52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.txt has 5000 nodes, 19982 edges, avg. degree = 7.9928, diameter = 6\n",
      "1.txt has 5000 nodes, 19981 edges, avg. degree = 7.9924, diameter = 6\n",
      "10.txt has 5000 nodes, 19980 edges, avg. degree = 7.992, diameter = 6\n",
      "11.txt has 5000 nodes, 19983 edges, avg. degree = 7.9932, diameter = 6\n",
      "12.txt has 5000 nodes, 19983 edges, avg. degree = 7.9932, diameter = 6\n",
      "13.txt has 5000 nodes, 19984 edges, avg. degree = 7.9936, diameter = 6\n",
      "14.txt has 5000 nodes, 19982 edges, avg. degree = 7.9928, diameter = 6\n",
      "15.txt has 5000 nodes, 19984 edges, avg. degree = 7.9936, diameter = 6\n",
      "16.txt has 5000 nodes, 19982 edges, avg. degree = 7.9928, diameter = 6\n",
      "17.txt has 5000 nodes, 19981 edges, avg. degree = 7.9924, diameter = 6\n",
      "18.txt has 5000 nodes, 19984 edges, avg. degree = 7.9936, diameter = 6\n",
      "19.txt has 5000 nodes, 19981 edges, avg. degree = 7.9924, diameter = 6\n",
      "2.txt has 5000 nodes, 19980 edges, avg. degree = 7.992, diameter = 6\n",
      "20.txt has 5000 nodes, 19983 edges, avg. degree = 7.9932, diameter = 6\n",
      "21.txt has 5000 nodes, 19982 edges, avg. degree = 7.9928, diameter = 6\n",
      "22.txt has 5000 nodes, 19982 edges, avg. degree = 7.9928, diameter = 6\n",
      "23.txt has 5000 nodes, 19981 edges, avg. degree = 7.9924, diameter = 6\n",
      "24.txt has 5000 nodes, 19984 edges, avg. degree = 7.9936, diameter = 6\n",
      "25.txt has 5000 nodes, 19982 edges, avg. degree = 7.9928, diameter = 6\n",
      "26.txt has 5000 nodes, 19984 edges, avg. degree = 7.9936, diameter = 6\n",
      "27.txt has 5000 nodes, 19983 edges, avg. degree = 7.9932, diameter = 6\n",
      "28.txt has 5000 nodes, 19982 edges, avg. degree = 7.9928, diameter = 6\n",
      "29.txt has 5000 nodes, 19983 edges, avg. degree = 7.9932, diameter = 6\n",
      "3.txt has 5000 nodes, 19982 edges, avg. degree = 7.9928, diameter = 6\n",
      "4.txt has 5000 nodes, 19984 edges, avg. degree = 7.9936, diameter = 6\n",
      "5.txt has 5000 nodes, 19981 edges, avg. degree = 7.9924, diameter = 6\n",
      "6.txt has 5000 nodes, 19984 edges, avg. degree = 7.9936, diameter = 6\n",
      "7.txt has 5000 nodes, 19983 edges, avg. degree = 7.9932, diameter = 6\n",
      "8.txt has 5000 nodes, 19983 edges, avg. degree = 7.9932, diameter = 6\n",
      "9.txt has 5000 nodes, 19984 edges, avg. degree = 7.9936, diameter = 6\n",
      "com-youtube.txt has 1134890 nodes, 2987624 edges\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "dpath = \".\\\\data\\\\\"\n",
    "gList = dict()\n",
    "filenames = []\n",
    "\n",
    "for root, dirs, files in os.walk(dpath):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if 'score' not in file:\n",
    "            filenames.append(file)\n",
    "            # Process nodes and edges\n",
    "            gList[file] = dict()\n",
    "            gList[file]['graph']=nx.Graph()\n",
    "            with open(file_path,'r') as f:\n",
    "                content = f.readlines()\n",
    "                edges = []\n",
    "                for line in content:\n",
    "                    if 'com' not in file:\n",
    "                        nodes = line[:-1].split('\\t')\n",
    "                    else:\n",
    "                        #continue # after finish all code run code with com\n",
    "                        nodes = line[:-1].split(\" \")\n",
    "                    # Create edge tuple and append\n",
    "                    edges.append((int(nodes[0]),int(nodes[1])))\n",
    "                gList[file]['graph'].add_edges_from(edges)\n",
    "                if 'com' not in file:\n",
    "                    avg_deg = np.mean(list(dict(sorted(dict(gList[file]['graph'].degree()).items())).values()))\n",
    "                    diameter = nx.diameter(gList[file]['graph'])\n",
    "                    print(\"{} has {} nodes, {} edges, avg. degree = {}, diameter = {}\".format(file,gList[file]['graph'].number_of_nodes(),gList[file]['graph'].number_of_edges(),avg_deg,diameter))\n",
    "                else:\n",
    "                    print(\"{} has {} nodes, {} edges\".format(file,gList[file]['graph'].number_of_nodes(),gList[file]['graph'].number_of_edges()))\n",
    "            \n",
    "            # Process scores\n",
    "            scorefile = file.replace(\".txt\",\"_score.txt\")\n",
    "            gList[file]['score'] = dict()\n",
    "            score_file_path = os.path.join(root,scorefile) \n",
    "            with open(score_file_path,'r') as f:\n",
    "                content = f.readlines()\n",
    "                for line in content:\n",
    "                    if 'com' not in file:\n",
    "                        node_score = line[:-1].split('\\t')\n",
    "                        gList[file]['score'][int(node_score[0])] = float(node_score[1])\n",
    "                    else:\n",
    "                        #continue # after finish all code run code with com\n",
    "                        node_score = line[:-1].split()\n",
    "                        gList[file]['score'][int(node_score[0][:-1])] = float(node_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd0956",
   "metadata": {},
   "source": [
    "# 3. DrBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e286c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing use\n",
    "G = gList['0.txt']['graph']\n",
    "y = torch.tensor(list(gList['0.txt']['score'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b72b7254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare nodes initial feature X [dv,1,1]\n",
    "def gen_nodes_feature(G):\n",
    "    deg = np.array(list(dict(sorted(dict(G.degree()).items())).values()))\n",
    "    X = np.ones((3,len(deg)))\n",
    "    X[0,:]=deg\n",
    "    norms = np.linalg.norm(X,axis = 1,keepdims=True)\n",
    "    X = torch.FloatTensor(X.T)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d99f2d",
   "metadata": {},
   "source": [
    "## 3a. DrBC encoder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd220ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class DrBCEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers,G):\n",
    "        super(DrBCEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.layer1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.norm1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.gru_cells = nn.GRUCell(hidden_size, hidden_size)\n",
    "        self.norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.G = G\n",
    "        self.deg = dict(self.G.degree())\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.norm1(x)\n",
    "        output = [x]\n",
    "        for i in range(self.num_layers-1):\n",
    "            hn = self.calHn(x)\n",
    "            x = self.gru_cells(hn,x)\n",
    "            x = self.norm2(x)\n",
    "            output.append(x)\n",
    "        output, _ = torch.max(torch.stack(output), dim=0)\n",
    "        return output\n",
    "\n",
    "    def calHn(self,x):\n",
    "        hn = torch.zeros(x.shape).to(self.device)\n",
    "        for node in self.G.nodes():\n",
    "            degv = self.deg[node]\n",
    "            for neigh in list(self.G.adj[node]):\n",
    "                denominator = 1/(math.sqrt(degv+1)*math.sqrt(self.deg[neigh]+1))\n",
    "                hn[node,:] += (denominator*x[neigh])\n",
    "        return hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c7cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrBCEncoder2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,G):\n",
    "        super(DrBCEncoder2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.norm1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.gru_cell1 = nn.GRUCell(hidden_size, hidden_size)\n",
    "        self.gru_cell2 = nn.GRUCell(hidden_size, hidden_size)\n",
    "        self.gru_cell3 = nn.GRUCell(hidden_size, hidden_size)\n",
    "        self.gru_cell4 = nn.GRUCell(hidden_size, hidden_size)\n",
    "        self.gru_cell5 = nn.GRUCell(hidden_size, hidden_size)\n",
    "        self.norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.norm4 = nn.BatchNorm1d(hidden_size)\n",
    "        self.norm5 = nn.BatchNorm1d(hidden_size)\n",
    "        self.norm6 = nn.BatchNorm1d(hidden_size)\n",
    "        self.G = G\n",
    "        self.deg = dict(self.G.degree())\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.norm1(x)\n",
    "        output = [x]\n",
    "\n",
    "        hn = self.calHn(x)\n",
    "        x = self.gru_cell1(hn,x)\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        hn = self.calHn(x)\n",
    "        x = self.gru_cell2(hn,x)\n",
    "        x = self.norm3(x)\n",
    "        \n",
    "        hn = self.calHn(x)\n",
    "        x = self.gru_cell3(hn,x)\n",
    "        x = self.norm4(x)\n",
    "        \n",
    "        hn = self.calHn(x)\n",
    "        x = self.gru_cell4(hn,x)\n",
    "        x = self.norm5(x)\n",
    "        \n",
    "        hn = self.calHn(x)\n",
    "        x = self.gru_cell5(hn,x)\n",
    "        x = self.norm6(x)\n",
    "        \n",
    "        output.append(x)\n",
    "        output, _ = torch.max(torch.stack(output), dim=0)\n",
    "        return output\n",
    "\n",
    "    def calHn(self,x):\n",
    "        hn = torch.zeros(x.shape).to(self.device)\n",
    "        for node in self.G.nodes():\n",
    "            degv = self.deg[node]\n",
    "            for neigh in list(self.G.adj[node]):\n",
    "                denominator = 1/(math.sqrt(degv+1)*math.sqrt(self.deg[neigh]+1))\n",
    "                hn[node,:] += (denominator*x[neigh])\n",
    "        return hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac5ecef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing the model state_dict\n",
      "layer1.weight \t torch.Size([128, 3])\n",
      "layer1.bias \t torch.Size([128])\n",
      "norm1.weight \t torch.Size([128])\n",
      "norm1.bias \t torch.Size([128])\n",
      "norm1.running_mean \t torch.Size([128])\n",
      "norm1.running_var \t torch.Size([128])\n",
      "norm1.num_batches_tracked \t torch.Size([])\n",
      "gru_cell1.weight_ih \t torch.Size([384, 128])\n",
      "gru_cell1.weight_hh \t torch.Size([384, 128])\n",
      "gru_cell1.bias_ih \t torch.Size([384])\n",
      "gru_cell1.bias_hh \t torch.Size([384])\n",
      "gru_cell2.weight_ih \t torch.Size([384, 128])\n",
      "gru_cell2.weight_hh \t torch.Size([384, 128])\n",
      "gru_cell2.bias_ih \t torch.Size([384])\n",
      "gru_cell2.bias_hh \t torch.Size([384])\n",
      "gru_cell3.weight_ih \t torch.Size([384, 128])\n",
      "gru_cell3.weight_hh \t torch.Size([384, 128])\n",
      "gru_cell3.bias_ih \t torch.Size([384])\n",
      "gru_cell3.bias_hh \t torch.Size([384])\n",
      "gru_cell4.weight_ih \t torch.Size([384, 128])\n",
      "gru_cell4.weight_hh \t torch.Size([384, 128])\n",
      "gru_cell4.bias_ih \t torch.Size([384])\n",
      "gru_cell4.bias_hh \t torch.Size([384])\n",
      "gru_cell5.weight_ih \t torch.Size([384, 128])\n",
      "gru_cell5.weight_hh \t torch.Size([384, 128])\n",
      "gru_cell5.bias_ih \t torch.Size([384])\n",
      "gru_cell5.bias_hh \t torch.Size([384])\n",
      "norm2.weight \t torch.Size([128])\n",
      "norm2.bias \t torch.Size([128])\n",
      "norm2.running_mean \t torch.Size([128])\n",
      "norm2.running_var \t torch.Size([128])\n",
      "norm2.num_batches_tracked \t torch.Size([])\n",
      "norm3.weight \t torch.Size([128])\n",
      "norm3.bias \t torch.Size([128])\n",
      "norm3.running_mean \t torch.Size([128])\n",
      "norm3.running_var \t torch.Size([128])\n",
      "norm3.num_batches_tracked \t torch.Size([])\n",
      "norm4.weight \t torch.Size([128])\n",
      "norm4.bias \t torch.Size([128])\n",
      "norm4.running_mean \t torch.Size([128])\n",
      "norm4.running_var \t torch.Size([128])\n",
      "norm4.num_batches_tracked \t torch.Size([])\n",
      "norm5.weight \t torch.Size([128])\n",
      "norm5.bias \t torch.Size([128])\n",
      "norm5.running_mean \t torch.Size([128])\n",
      "norm5.running_var \t torch.Size([128])\n",
      "norm5.num_batches_tracked \t torch.Size([])\n",
      "norm6.weight \t torch.Size([128])\n",
      "norm6.bias \t torch.Size([128])\n",
      "norm6.running_mean \t torch.Size([128])\n",
      "norm6.running_var \t torch.Size([128])\n",
      "norm6.num_batches_tracked \t torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "input_size = 3\n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "num_layers = 5\n",
    "encoder = DrBCEncoder2(input_size, hidden_size,G)\n",
    "print(\"Accessing the model state_dict\")\n",
    "for values in encoder.state_dict():\n",
    "    print(values, \"\\t\", encoder.state_dict()[values].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81ebdc3",
   "metadata": {},
   "source": [
    "## 3b. Decoder: 2-layer MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a345a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrBCDecoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DrBCDecoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Define the layers of the decoder\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.norm1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "        self.norm2 = nn.BatchNorm1d(output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input through the layers of the decoder\n",
    "        x = self.layer1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.norm2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e17db1",
   "metadata": {},
   "source": [
    "## 3c. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d8e81fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(minimum,maximum,qty):\n",
    "    pairs = []\n",
    "    for i in range(qty):\n",
    "        a = random.randint(minimum,maximum)\n",
    "        b = random.randint(minimum,maximum)\n",
    "        pairs.append((a,b))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "300596cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bc_pairs(pairs, outputs, y):\n",
    "    pred = []\n",
    "    gt = []\n",
    "    g = nn.Sigmoid()\n",
    "    for i, pair in enumerate(pairs):\n",
    "        pred.append(g(outputs[pair[0]] - outputs[pair[1]]))\n",
    "        gt.append(g(y[pair[0]] - y[pair[1]]))\n",
    "    return torch.stack(pred), torch.stack(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f93fd418",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEarlyStopping:\n",
    "    def __init__(self, tolerance=5, min_delta=0):\n",
    "\n",
    "        self.tolerance = tolerance\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, train_loss,last_train_loss):\n",
    "        if abs(train_loss - last_train_loss) < self.min_delta:\n",
    "            self.counter +=1\n",
    "            if self.counter >= self.tolerance:  \n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e342b506",
   "metadata": {},
   "source": [
    "# 4. Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e682e9af",
   "metadata": {},
   "source": [
    "## 4a. Top-N% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73a618b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topN(n,pred,gt):\n",
    "    k = math.ceil(pred.size()[0]*n/100)\n",
    "    _,pred_top = torch.topk(pred.view(-1),k=k)\n",
    "    _,gt_top = torch.topk(gt.view(-1),k=k)\n",
    "    intersect = torch.unique(torch.cat((pred_top,gt_top),0))\n",
    "    acc = (2*k-len(intersect))/k\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca4c84e",
   "metadata": {},
   "source": [
    "## 4b. Kendall tau distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f0dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemented by kendalltau from scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "561ecfc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3333333333333334"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4])\n",
    "b = torch.tensor([4,2,1,3])\n",
    "kendalltau(a,b).correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02e3bda",
   "metadata": {},
   "source": [
    "## 4c. Wall-clock running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c2e6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# The implementation is combine with the final function \n",
    "# that will be defined afterward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b437c0",
   "metadata": {},
   "source": [
    "# 5. Putting all things together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ffab299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "087324d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_result_for_once(filename,episodes = 20):\n",
    "    start_time = time.time()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    k = [1,5,10]\n",
    "    \n",
    "    print(\"Working on {}\".format(filename))\n",
    "    # Prepare the data\n",
    "    G = gList[filename]['graph']\n",
    "    y = torch.tensor([list(gList[filename]['score'].values())])\n",
    "    y = torch.transpose(y,0,1)\n",
    "\n",
    "    # Define the models\n",
    "    input_size = 3\n",
    "    hidden_size = 128\n",
    "    output_size = 1\n",
    "\n",
    "    encoder = DrBCEncoder2(input_size, hidden_size,G)\n",
    "    decoder = DrBCDecoder(hidden_size,hidden_size,output_size)\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    model = EncoderDecoder(encoder,decoder)\n",
    "    model.to(device)\n",
    "    early_stopping = MyEarlyStopping(tolerance=5, min_delta=1)\n",
    "    \n",
    "    n = G.number_of_nodes()\n",
    "    num_episodes = episodes #10000\n",
    "    lr = 0.0001\n",
    "    sample_qty = 5*n\n",
    "\n",
    "    # Define the loss and optimizer\n",
    "    criterion = nn.BCELoss(reduction = 'sum')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the inputs\n",
    "    inputs = gen_nodes_feature(G)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_model_weights = None\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Start training on {}\".format(device))\n",
    "    pairs = sampling(0,n-1,sample_qty)\n",
    "    loss_list = [float('inf')]\n",
    "    for episode in range(num_episodes):\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # model\n",
    "        outputs = model(inputs)\n",
    "        pred,gt = bc_pairs(pairs,outputs,y)\n",
    "        loss = criterion(pred,gt)\n",
    "        loss_list.append(loss)\n",
    "        if ~loss.requires_grad:\n",
    "            loss.requires_grad_()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        early_stopping(loss,loss_list[-2])\n",
    "        \n",
    "        if best_loss>loss:\n",
    "            best_loss = loss\n",
    "            best_out = outputs\n",
    "            best_model_weights = model.state_dict()\n",
    "\n",
    "        # Print statistics\n",
    "        #if episode%5 == 4:\n",
    "        print('[%d] loss: %.4f' %(episode + 1, loss.item()))\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    \n",
    "    torch.save(best_model_weights, './model_pth/best_model_{}.pth'.format(num_episodes))\n",
    "    print(best_out)\n",
    "    top1 = topN(1,best_out,y)\n",
    "    top5 = topN(5,best_out,y)\n",
    "    top10 = topN(10,best_out,y)\n",
    "    ken,_ = kendalltau(best_out.flatten().to('cpu').detach().numpy(),y.flatten().to('cpu').detach().numpy())\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time-start_time\n",
    "    print(\"Elapsed time: {:.2f} seconds\".format(elapsed_time))\n",
    "    return top1,top5,top10,ken,elapsed_time,model,loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfeeaae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_file(filename,pth):\n",
    "    start_time = time.time()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    k = [1,5,10]\n",
    "    \n",
    "    print(\"Testing on {}\".format(filename))\n",
    "    # Prepare the data\n",
    "    G = gList[filename]['graph']\n",
    "    y = torch.tensor([list(gList[filename]['score'].values())])\n",
    "    y = torch.transpose(y,0,1)\n",
    "\n",
    "    # Define the models\n",
    "    input_size = 3\n",
    "    hidden_size = 128\n",
    "    output_size = 1\n",
    "\n",
    "    encoder = DrBCEncoder2(input_size, hidden_size,G)\n",
    "    decoder = DrBCDecoder(hidden_size,hidden_size,output_size)\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    model = EncoderDecoder(encoder,decoder)\n",
    "    model.to(device)\n",
    "\n",
    "    # Get the inputs\n",
    "    inputs = gen_nodes_feature(G)\n",
    "    inputs = inputs.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    # Test the model\n",
    "    model.load_state_dict(torch.load(pth))\n",
    "    model.eval()\n",
    "    output = model(inputs)\n",
    "    \n",
    "    top1 = topN(1,output,y)\n",
    "    top5 = topN(5,output,y)\n",
    "    top10 = topN(10,output,y)\n",
    "    ken,_ = kendalltau(output.flatten().to('cpu').detach().numpy(),y.flatten().to('cpu').detach().numpy())\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time-start_time\n",
    "    print(\"Top-1% accuracy: {:.2f}\".format(top1))\n",
    "    print(\"Top-5% accuracy: {:.2f}\".format(top5))\n",
    "    print(\"Top-10% accuracy: {:.2f}\".format(top10))\n",
    "    print(\"Kendall tau distance: {:.2f}\".format(ken))\n",
    "    print(\"Elapsed time: {:.2f} seconds\".format(elapsed_time))\n",
    "    return top1,top5,top10,ken,elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ade6c9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 1.txt\n",
      "Start training on cuda\n",
      "[1] loss: 20948.7656\n",
      "[2] loss: 21024.8438\n",
      "[3] loss: 20658.8711\n",
      "[4] loss: 20363.6719\n",
      "[5] loss: 20186.0547\n",
      "[6] loss: 20057.0469\n",
      "[7] loss: 19944.2637\n",
      "[8] loss: 19847.8828\n",
      "[9] loss: 19765.1250\n",
      "[10] loss: 19689.4570\n",
      "tensor([[2.5229e+01],\n",
      "        [2.8183e+01],\n",
      "        [5.4161e+00],\n",
      "        ...,\n",
      "        [1.4451e-01],\n",
      "        [8.9481e-02],\n",
      "        [1.1869e-02]], device='cuda:0', grad_fn=<NativeBatchNormBackward0>)\n",
      "Elapsed time: 1249.85 seconds\n",
      "Top-1% accuracy: 0.46\n",
      "Top-5% accuracy: 0.13\n",
      "Top-10% accuracy: 0.11\n",
      "Kendall tau distance: -0.15\n",
      "Running time: 1249.85\n"
     ]
    }
   ],
   "source": [
    "once_top1,once_top5,once_top10,once_ken,once_elapsed_time,model_once,once_loss_list = train_and_result_for_once(filenames[1],episodes = 10)\n",
    "print(\"Top-1% accuracy: {:.2f}\".format(once_top1))\n",
    "print(\"Top-5% accuracy: {:.2f}\".format(once_top5))\n",
    "print(\"Top-10% accuracy: {:.2f}\".format(once_top10))\n",
    "print(\"Kendall tau distance: {:.2f}\".format(once_ken))\n",
    "print(\"Running time: {:.2f}\".format(once_elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "14611756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(20948.766, dtype=float32),\n",
       " array(21024.844, dtype=float32),\n",
       " array(20658.871, dtype=float32),\n",
       " array(20363.672, dtype=float32),\n",
       " array(20186.055, dtype=float32),\n",
       " array(20057.047, dtype=float32),\n",
       " array(19944.264, dtype=float32),\n",
       " array(19847.883, dtype=float32),\n",
       " array(19765.125, dtype=float32),\n",
       " array(19689.457, dtype=float32)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "once_loss_list_after = once_loss_list[1:]\n",
    "loss_list = [loss.cpu().detach().numpy() for loss in once_loss_list_after]\n",
    "loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9317d81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x164a074e2c8>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(loss_list),'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "721794c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 0.txt\n",
      "Top-1% accuracy: 0.98\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.84\n",
      "Kendall tau distance: 0.50\n",
      "Elapsed time: 23.49 seconds\n",
      "Testing on 1.txt\n",
      "Top-1% accuracy: 0.92\n",
      "Top-5% accuracy: 0.92\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.50\n",
      "Elapsed time: 22.75 seconds\n",
      "Testing on 10.txt\n",
      "Top-1% accuracy: 0.92\n",
      "Top-5% accuracy: 0.89\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.53\n",
      "Elapsed time: 22.67 seconds\n",
      "Testing on 11.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.85\n",
      "Top-10% accuracy: 0.83\n",
      "Kendall tau distance: 0.53\n",
      "Elapsed time: 22.81 seconds\n",
      "Testing on 12.txt\n",
      "Top-1% accuracy: 0.92\n",
      "Top-5% accuracy: 0.85\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.51\n",
      "Elapsed time: 23.25 seconds\n",
      "Testing on 13.txt\n",
      "Top-1% accuracy: 0.90\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.83\n",
      "Kendall tau distance: 0.52\n",
      "Elapsed time: 22.89 seconds\n",
      "Testing on 14.txt\n",
      "Top-1% accuracy: 0.94\n",
      "Top-5% accuracy: 0.84\n",
      "Top-10% accuracy: 0.86\n",
      "Kendall tau distance: 0.50\n",
      "Elapsed time: 22.85 seconds\n",
      "Testing on 15.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.87\n",
      "Kendall tau distance: 0.51\n",
      "Elapsed time: 22.85 seconds\n",
      "Testing on 16.txt\n",
      "Top-1% accuracy: 0.92\n",
      "Top-5% accuracy: 0.86\n",
      "Top-10% accuracy: 0.88\n",
      "Kendall tau distance: 0.49\n",
      "Elapsed time: 22.46 seconds\n",
      "Testing on 17.txt\n",
      "Top-1% accuracy: 0.94\n",
      "Top-5% accuracy: 0.87\n",
      "Top-10% accuracy: 0.84\n",
      "Kendall tau distance: 0.52\n",
      "Elapsed time: 22.85 seconds\n",
      "Testing on 18.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.90\n",
      "Top-10% accuracy: 0.83\n",
      "Kendall tau distance: 0.50\n",
      "Elapsed time: 22.43 seconds\n",
      "Testing on 19.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.89\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.51\n",
      "Elapsed time: 22.68 seconds\n",
      "Testing on 2.txt\n",
      "Top-1% accuracy: 0.90\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.49\n",
      "Elapsed time: 22.78 seconds\n",
      "Testing on 20.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.87\n",
      "Kendall tau distance: 0.50\n",
      "Elapsed time: 22.67 seconds\n",
      "Testing on 21.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.86\n",
      "Top-10% accuracy: 0.84\n",
      "Kendall tau distance: 0.51\n",
      "Elapsed time: 22.80 seconds\n",
      "Testing on 22.txt\n",
      "Top-1% accuracy: 0.94\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.86\n",
      "Kendall tau distance: 0.48\n",
      "Elapsed time: 22.91 seconds\n",
      "Testing on 23.txt\n",
      "Top-1% accuracy: 0.92\n",
      "Top-5% accuracy: 0.87\n",
      "Top-10% accuracy: 0.87\n",
      "Kendall tau distance: 0.50\n",
      "Elapsed time: 22.95 seconds\n",
      "Testing on 24.txt\n",
      "Top-1% accuracy: 0.92\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.86\n",
      "Kendall tau distance: 0.50\n",
      "Elapsed time: 22.48 seconds\n",
      "Testing on 25.txt\n",
      "Top-1% accuracy: 0.94\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.87\n",
      "Kendall tau distance: 0.50\n",
      "Elapsed time: 22.63 seconds\n",
      "Testing on 26.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.89\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.50\n",
      "Elapsed time: 22.88 seconds\n",
      "Testing on 27.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.86\n",
      "Kendall tau distance: 0.49\n",
      "Elapsed time: 22.78 seconds\n",
      "Testing on 28.txt\n",
      "Top-1% accuracy: 0.94\n",
      "Top-5% accuracy: 0.89\n",
      "Top-10% accuracy: 0.84\n",
      "Kendall tau distance: 0.51\n",
      "Elapsed time: 22.51 seconds\n",
      "Testing on 29.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.91\n",
      "Top-10% accuracy: 0.86\n",
      "Kendall tau distance: 0.51\n",
      "Elapsed time: 22.34 seconds\n",
      "Testing on 3.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.87\n",
      "Top-10% accuracy: 0.84\n",
      "Kendall tau distance: 0.49\n",
      "Elapsed time: 22.50 seconds\n",
      "Testing on 4.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.87\n",
      "Top-10% accuracy: 0.86\n",
      "Kendall tau distance: 0.52\n",
      "Elapsed time: 23.30 seconds\n",
      "Testing on 5.txt\n",
      "Top-1% accuracy: 0.92\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.84\n",
      "Kendall tau distance: 0.50\n",
      "Elapsed time: 22.67 seconds\n",
      "Testing on 6.txt\n",
      "Top-1% accuracy: 0.90\n",
      "Top-5% accuracy: 0.89\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.48\n",
      "Elapsed time: 22.92 seconds\n",
      "Testing on 7.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.90\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.49\n",
      "Elapsed time: 22.52 seconds\n",
      "Testing on 8.txt\n",
      "Top-1% accuracy: 0.90\n",
      "Top-5% accuracy: 0.87\n",
      "Top-10% accuracy: 0.88\n",
      "Kendall tau distance: 0.50\n",
      "Elapsed time: 22.77 seconds\n",
      "Testing on 9.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.89\n",
      "Top-10% accuracy: 0.88\n",
      "Kendall tau distance: 0.50\n",
      "Elapsed time: 22.97 seconds\n",
      "\n",
      "Overall:\n",
      "Top-1% accuracy: 0.94±0.02\n",
      "Top-5% accuracy: 0.88±0.02\n",
      "Top-10% accuracy: 0.85±0.01\n",
      "Kendall tau distance: 0.50±0.01\n",
      "Running time: 22.78±0.25\n"
     ]
    }
   ],
   "source": [
    "top1_list = []\n",
    "top5_list = []\n",
    "top10_list = []\n",
    "ken_list = []\n",
    "elapsed_time_list = []\n",
    "for filename in filenames[:-1]:\n",
    "    top1,top5,top10,ken,elapsed_time = test_file(filename,\"./model_pth/best_model_10_old.pth\")\n",
    "    top1_list.append(top1)\n",
    "    top5_list.append(top5)\n",
    "    top10_list.append(top10)\n",
    "    ken_list.append(ken)\n",
    "    elapsed_time_list.append(elapsed_time)\n",
    "\n",
    "# Calculate Mean for each evaluation metrics:\n",
    "print()\n",
    "print(\"Overall:\")\n",
    "print(\"Top-1% accuracy: {:.2f}±{:.2f}\".format(np.mean(np.array(top1_list)),np.std(np.array(top1_list))))\n",
    "print(\"Top-5% accuracy: {:.2f}±{:.2f}\".format(np.mean(np.array(top5_list)),np.std(np.array(top5_list))))\n",
    "print(\"Top-10% accuracy: {:.2f}±{:.2f}\".format(np.mean(np.array(top10_list)),np.std(np.array(top10_list))))\n",
    "print(\"Kendall tau distance: {:.2f}±{:.2f}\".format(np.mean(np.array(ken_list)),np.std(np.array(ken_list))))\n",
    "print(\"Running time: {:.2f}±{:.2f}\".format(np.mean(np.array(elapsed_time_list)),np.std(np.array(elapsed_time_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf97b0d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 0.txt\n",
      "Top-1% accuracy: 0.98\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.83\n",
      "Kendall tau distance: 0.42\n",
      "Elapsed time: 25.76 seconds\n",
      "Testing on 1.txt\n",
      "Top-1% accuracy: 0.94\n",
      "Top-5% accuracy: 0.91\n",
      "Top-10% accuracy: 0.86\n",
      "Kendall tau distance: 0.41\n",
      "Elapsed time: 9.12 seconds\n",
      "Testing on 10.txt\n",
      "Top-1% accuracy: 0.94\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.42\n",
      "Elapsed time: 8.47 seconds\n",
      "Testing on 11.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.85\n",
      "Top-10% accuracy: 0.83\n",
      "Kendall tau distance: 0.46\n",
      "Elapsed time: 8.01 seconds\n",
      "Testing on 12.txt\n",
      "Top-1% accuracy: 0.92\n",
      "Top-5% accuracy: 0.85\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.42\n",
      "Elapsed time: 8.47 seconds\n",
      "Testing on 13.txt\n",
      "Top-1% accuracy: 0.90\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.83\n",
      "Kendall tau distance: 0.46\n",
      "Elapsed time: 9.20 seconds\n",
      "Testing on 14.txt\n",
      "Top-1% accuracy: 0.94\n",
      "Top-5% accuracy: 0.84\n",
      "Top-10% accuracy: 0.86\n",
      "Kendall tau distance: 0.44\n",
      "Elapsed time: 8.96 seconds\n",
      "Testing on 15.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.87\n",
      "Kendall tau distance: 0.39\n",
      "Elapsed time: 7.94 seconds\n",
      "Testing on 16.txt\n",
      "Top-1% accuracy: 0.92\n",
      "Top-5% accuracy: 0.86\n",
      "Top-10% accuracy: 0.88\n",
      "Kendall tau distance: 0.40\n",
      "Elapsed time: 7.81 seconds\n",
      "Testing on 17.txt\n",
      "Top-1% accuracy: 0.94\n",
      "Top-5% accuracy: 0.86\n",
      "Top-10% accuracy: 0.83\n",
      "Kendall tau distance: 0.44\n",
      "Elapsed time: 6.86 seconds\n",
      "Testing on 18.txt\n",
      "Top-1% accuracy: 0.98\n",
      "Top-5% accuracy: 0.90\n",
      "Top-10% accuracy: 0.82\n",
      "Kendall tau distance: 0.42\n",
      "Elapsed time: 7.05 seconds\n",
      "Testing on 19.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.44\n",
      "Elapsed time: 6.71 seconds\n",
      "Testing on 2.txt\n",
      "Top-1% accuracy: 0.90\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.84\n",
      "Kendall tau distance: 0.43\n",
      "Elapsed time: 6.68 seconds\n",
      "Testing on 20.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.87\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.43\n",
      "Elapsed time: 6.68 seconds\n",
      "Testing on 21.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.85\n",
      "Top-10% accuracy: 0.84\n",
      "Kendall tau distance: 0.45\n",
      "Elapsed time: 6.68 seconds\n",
      "Testing on 22.txt\n",
      "Top-1% accuracy: 0.94\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.41\n",
      "Elapsed time: 6.95 seconds\n",
      "Testing on 23.txt\n",
      "Top-1% accuracy: 0.92\n",
      "Top-5% accuracy: 0.86\n",
      "Top-10% accuracy: 0.87\n",
      "Kendall tau distance: 0.42\n",
      "Elapsed time: 6.61 seconds\n",
      "Testing on 24.txt\n",
      "Top-1% accuracy: 0.92\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.39\n",
      "Elapsed time: 6.88 seconds\n",
      "Testing on 25.txt\n",
      "Top-1% accuracy: 0.94\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.87\n",
      "Kendall tau distance: 0.40\n",
      "Elapsed time: 6.71 seconds\n",
      "Testing on 26.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.83\n",
      "Kendall tau distance: 0.42\n",
      "Elapsed time: 6.29 seconds\n",
      "Testing on 27.txt\n",
      "Top-1% accuracy: 0.98\n",
      "Top-5% accuracy: 0.88\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.43\n",
      "Elapsed time: 6.28 seconds\n",
      "Testing on 28.txt\n",
      "Top-1% accuracy: 0.94\n",
      "Top-5% accuracy: 0.89\n",
      "Top-10% accuracy: 0.82\n",
      "Kendall tau distance: 0.44\n",
      "Elapsed time: 6.53 seconds\n",
      "Testing on 29.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.90\n",
      "Top-10% accuracy: 0.84\n",
      "Kendall tau distance: 0.40\n",
      "Elapsed time: 6.90 seconds\n",
      "Testing on 3.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.86\n",
      "Top-10% accuracy: 0.83\n",
      "Kendall tau distance: 0.42\n",
      "Elapsed time: 7.07 seconds\n",
      "Testing on 4.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.87\n",
      "Top-10% accuracy: 0.85\n",
      "Kendall tau distance: 0.42\n",
      "Elapsed time: 6.82 seconds\n",
      "Testing on 5.txt\n",
      "Top-1% accuracy: 0.92\n",
      "Top-5% accuracy: 0.89\n",
      "Top-10% accuracy: 0.82\n",
      "Kendall tau distance: 0.44\n",
      "Elapsed time: 6.66 seconds\n",
      "Testing on 6.txt\n",
      "Top-1% accuracy: 0.90\n",
      "Top-5% accuracy: 0.89\n",
      "Top-10% accuracy: 0.84\n",
      "Kendall tau distance: 0.41\n",
      "Elapsed time: 6.50 seconds\n",
      "Testing on 7.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.89\n",
      "Top-10% accuracy: 0.84\n",
      "Kendall tau distance: 0.41\n",
      "Elapsed time: 6.60 seconds\n",
      "Testing on 8.txt\n",
      "Top-1% accuracy: 0.90\n",
      "Top-5% accuracy: 0.85\n",
      "Top-10% accuracy: 0.88\n",
      "Kendall tau distance: 0.43\n",
      "Elapsed time: 7.08 seconds\n",
      "Testing on 9.txt\n",
      "Top-1% accuracy: 0.96\n",
      "Top-5% accuracy: 0.89\n",
      "Top-10% accuracy: 0.87\n",
      "Kendall tau distance: 0.40\n",
      "Elapsed time: 6.64 seconds\n",
      "\n",
      "Overall:\n",
      "Top-1% accuracy: 0.94±0.02\n",
      "Top-5% accuracy: 0.88±0.02\n",
      "Top-10% accuracy: 0.85±0.02\n",
      "Kendall tau distance: 0.42±0.02\n",
      "Running time: 7.83±3.43\n"
     ]
    }
   ],
   "source": [
    "top1_list = []\n",
    "top5_list = []\n",
    "top10_list = []\n",
    "ken_list = []\n",
    "elapsed_time_list = []\n",
    "for filename in filenames[:-1]:\n",
    "    top1,top5,top10,ken,elapsed_time = test_file(filename,\"./model_pth/best_model_10.pth\")\n",
    "    top1_list.append(top1)\n",
    "    top5_list.append(top5)\n",
    "    top10_list.append(top10)\n",
    "    ken_list.append(ken)\n",
    "    elapsed_time_list.append(elapsed_time)\n",
    "\n",
    "# Calculate Mean for each evaluation metrics:\n",
    "print()\n",
    "print(\"Overall:\")\n",
    "print(\"Top-1% accuracy: {:.2f}±{:.2f}\".format(np.mean(np.array(top1_list)),np.std(np.array(top1_list))))\n",
    "print(\"Top-5% accuracy: {:.2f}±{:.2f}\".format(np.mean(np.array(top5_list)),np.std(np.array(top5_list))))\n",
    "print(\"Top-10% accuracy: {:.2f}±{:.2f}\".format(np.mean(np.array(top10_list)),np.std(np.array(top10_list))))\n",
    "print(\"Kendall tau distance: {:.2f}±{:.2f}\".format(np.mean(np.array(ken_list)),np.std(np.array(ken_list))))\n",
    "print(\"Running time: {:.2f}±{:.2f}\".format(np.mean(np.array(elapsed_time_list)),np.std(np.array(elapsed_time_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b431b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on com-youtube.txt\n"
     ]
    }
   ],
   "source": [
    "top1,top5,top10,ken,elapsed_time = test_file(filenames[-1],\"./model_pth/best_model_10.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
