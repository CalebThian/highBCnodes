{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbf6a13",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eb22d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206514a0",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing  \n",
    "Data Structure:\n",
    "1. **gList** <Dict>: containing total 31 graphs, which 30 from Synthetic and 1 from youtube,using filename as key  \n",
    "2. element of gList <Dict>: 'graph':nx.Graph();'score': <Dict> with 'node' and 'score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b0a52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.txt has 5000 nodes, 19982 edges\n",
      "1.txt has 5000 nodes, 19981 edges\n",
      "10.txt has 5000 nodes, 19980 edges\n",
      "11.txt has 5000 nodes, 19983 edges\n",
      "12.txt has 5000 nodes, 19983 edges\n",
      "13.txt has 5000 nodes, 19984 edges\n",
      "14.txt has 5000 nodes, 19982 edges\n",
      "15.txt has 5000 nodes, 19984 edges\n",
      "16.txt has 5000 nodes, 19982 edges\n",
      "17.txt has 5000 nodes, 19981 edges\n",
      "18.txt has 5000 nodes, 19984 edges\n",
      "19.txt has 5000 nodes, 19981 edges\n",
      "2.txt has 5000 nodes, 19980 edges\n",
      "20.txt has 5000 nodes, 19983 edges\n",
      "21.txt has 5000 nodes, 19982 edges\n",
      "22.txt has 5000 nodes, 19982 edges\n",
      "23.txt has 5000 nodes, 19981 edges\n",
      "24.txt has 5000 nodes, 19984 edges\n",
      "25.txt has 5000 nodes, 19982 edges\n",
      "26.txt has 5000 nodes, 19984 edges\n",
      "27.txt has 5000 nodes, 19983 edges\n",
      "28.txt has 5000 nodes, 19982 edges\n",
      "29.txt has 5000 nodes, 19983 edges\n",
      "3.txt has 5000 nodes, 19982 edges\n",
      "4.txt has 5000 nodes, 19984 edges\n",
      "5.txt has 5000 nodes, 19981 edges\n",
      "6.txt has 5000 nodes, 19984 edges\n",
      "7.txt has 5000 nodes, 19983 edges\n",
      "8.txt has 5000 nodes, 19983 edges\n",
      "9.txt has 5000 nodes, 19984 edges\n",
      "com-youtube.txt has 0 nodes, 0 edges\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "dpath = \".\\\\data\\\\\"\n",
    "gList = dict()\n",
    "filenames = []\n",
    "\n",
    "for root, dirs, files in os.walk(dpath):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if 'score' not in file:\n",
    "            filenames.append(file)\n",
    "            # Process nodes and edges\n",
    "            gList[file] = dict()\n",
    "            gList[file]['graph']=nx.Graph()\n",
    "            with open(file_path,'r') as f:\n",
    "                content = f.readlines()\n",
    "                edges = []\n",
    "                for line in content:\n",
    "                    if 'com' not in file:\n",
    "                        nodes = line[:-1].split('\\t')\n",
    "                    else:\n",
    "                        continue # after finish all code run code with com\n",
    "                        nodes = line[:-1].split(\" \")\n",
    "                    # Create edge tuple and append\n",
    "                    edges.append((int(nodes[0]),int(nodes[1])))\n",
    "                gList[file]['graph'].add_edges_from(edges)\n",
    "                print(\"{} has {} nodes, {} edges\".format(file,gList[file]['graph'].number_of_nodes(),gList[file]['graph'].number_of_edges()))\n",
    "            \n",
    "            # Process scores\n",
    "            scorefile = file.replace(\".txt\",\"_score.txt\")\n",
    "            gList[file]['score'] = dict()\n",
    "            score_file_path = os.path.join(root,scorefile) \n",
    "            with open(score_file_path,'r') as f:\n",
    "                content = f.readlines()\n",
    "                for line in content:\n",
    "                    if 'com' not in file:\n",
    "                        node_score = line[:-1].split('\\t')\n",
    "                    else:\n",
    "                        continue # after finish all code run code with com\n",
    "                        node_score = line[:-1].split(\" \")\n",
    "                    gList[file]['score'][int(node_score[0])] = float(node_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd0956",
   "metadata": {},
   "source": [
    "# 3. DrBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e286c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = gList['0.txt']['graph']\n",
    "y = torch.tensor(list(gList['0.txt']['score'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b72b7254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare nodes initial feature X [dv,1,1]\n",
    "def gen_nodes_feature(G):\n",
    "    deg = np.array(list(dict(sorted(dict(G.degree()).items())).values()))\n",
    "    X = np.ones((3,len(deg)))\n",
    "    X[0,:]=deg\n",
    "    norms = np.linalg.norm(X,axis = 1,keepdims=True)\n",
    "    X = torch.FloatTensor(X.T)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34d9ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.X[index]\n",
    "        y = self.y[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d99f2d",
   "metadata": {},
   "source": [
    "## 3a. DrBC encoder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea51df6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Define the model\\ninput_size = 3\\nhidden_size = 32\\nnum_layers = 5\\nencoder = DrBCEncoder(input_size, hidden_size, num_layers,g)\\nX = gen_nodes_feature(g)\\nout = encoder(X)\\nprint(out.shape)\\nprint(out)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DrBCEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers,G):\n",
    "        super(DrBCEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.layer1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.norm1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.gru_cell = nn.GRUCell(hidden_size, hidden_size,bias = False)\n",
    "        self.norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.G = G\n",
    "        self.deg = dict(self.G.degree())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.norm1(x)\n",
    "        output = [x]\n",
    "        for i in range(self.num_layers-1):\n",
    "            hn = self.calHn(x)\n",
    "            x = self.gru_cell(x,hn)\n",
    "            x = self.norm2(x)\n",
    "            output.append(x)\n",
    "        output, _ = torch.max(torch.stack(output), dim=0)\n",
    "        return output\n",
    "\n",
    "    def calHn(self,x):\n",
    "        hn = torch.zeros(x.shape)\n",
    "        for node in self.G.nodes():\n",
    "            degv = self.deg[node]\n",
    "            for neigh in list(self.G.adj[node]):\n",
    "                denominator = 1/(math.sqrt(degv+1)*math.sqrt(self.deg[neigh]+1))\n",
    "                hn[node,:] += (denominator*x[neigh])\n",
    "        return hn\n",
    "    \n",
    "'''\n",
    "# Define the model\n",
    "input_size = 3\n",
    "hidden_size = 32\n",
    "num_layers = 5\n",
    "encoder = DrBCEncoder(input_size, hidden_size, num_layers,g)\n",
    "X = gen_nodes_feature(g)\n",
    "out = encoder(X)\n",
    "print(out.shape)\n",
    "print(out)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d8039",
   "metadata": {},
   "source": [
    "## 3b. Decoder: 2-layer MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68429211",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrBCDecoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DrBCDecoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Define the layers of the decoder\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.norm1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "        self.norm2 = nn.BatchNorm1d(output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input through the layers of the decoder\n",
    "        x = self.layer1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.norm2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa0437",
   "metadata": {},
   "source": [
    "## 3c. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08399b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(minimum,maximum,qty):\n",
    "    pairs = []\n",
    "    for i in range(qty):\n",
    "        a = random.randint(minimum,maximum)\n",
    "        b = random.randint(minimum,maximum)\n",
    "        pairs.append((a,b))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb8a6d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bc_pairs_old(pairs,pred,gt):\n",
    "    pred_dif = []\n",
    "    gt_dif = []\n",
    "    g = nn.Sigmoid()\n",
    "    for pair in pairs:\n",
    "        pred_dif.append(g(pred[pair[0]]-pred[pair[1]]))\n",
    "        gt_dif.append(g(gt[pair[0]]-gt[pair[1]]))\n",
    "    return torch.tensor(pred_dif),torch.tensor(gt_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "171f85e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bc_pairs(pairs, outputs, y):\n",
    "    pred = []\n",
    "    gt = []\n",
    "    for i, pair in enumerate(pairs):\n",
    "        pred.append(outputs[pair[0]] - outputs[pair[1]])\n",
    "        gt.append(y[pair[0]] > y[pair[1]])\n",
    "    return torch.stack(pred), torch.tensor(gt, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a876d991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nG = gList['0.txt']['graph']\\ny = torch.tensor([list(gList['0.txt']['score'].values())])\\ny = torch.transpose(y,0,1)\\n# Define the models\\ninput_size = 3\\nhidden_size = 128\\noutput_size = 1\\nnum_layers = 5\\nencoder = DrBCEncoder(input_size, hidden_size, num_layers,G)\\ndecoder = DrBCDecoder(hidden_size,hidden_size,output_size)\\n\\nn = G.number_of_nodes()\\nnum_episodes = 20\\nlr = 0.001\\nsample_qty = 5*n\\n\\n# Define the loss and optimizer\\ncriterion = nn.BCELoss(reduction = 'sum')\\noptimizer = optim.Adam(list(encoder.parameters())+list(decoder.parameters()), lr=lr)\\n\\n# Get the inputs\\ninputs = gen_nodes_feature(G)\\n\\n# Train the model\\nfor episode in range(num_episodes):\\n    # model\\n    outputs = encoder(inputs)\\n    outputs = decoder(outputs)\\n    \\n    pairs = sampling(0,n-1,sample_qty)\\n    pred,gt = bc_pairs(pairs,outputs,y)\\n    loss = criterion(pred,gt)\\n\\n    if ~loss.requires_grad:\\n        loss.requires_grad_()\\n        \\n    # Zero the parameter gradients\\n    optimizer.zero_grad()\\n    loss.backward()\\n    optimizer.step()\\n\\n    # Print statistics\\n    print('[%d] loss: %.4f' %(episode + 1, loss.item()))\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "G = gList['0.txt']['graph']\n",
    "y = torch.tensor([list(gList['0.txt']['score'].values())])\n",
    "y = torch.transpose(y,0,1)\n",
    "# Define the models\n",
    "input_size = 3\n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "num_layers = 5\n",
    "encoder = DrBCEncoder(input_size, hidden_size, num_layers,G)\n",
    "decoder = DrBCDecoder(hidden_size,hidden_size,output_size)\n",
    "\n",
    "n = G.number_of_nodes()\n",
    "num_episodes = 20\n",
    "lr = 0.001\n",
    "sample_qty = 5*n\n",
    "\n",
    "# Define the loss and optimizer\n",
    "criterion = nn.BCELoss(reduction = 'sum')\n",
    "optimizer = optim.Adam(list(encoder.parameters())+list(decoder.parameters()), lr=lr)\n",
    "\n",
    "# Get the inputs\n",
    "inputs = gen_nodes_feature(G)\n",
    "\n",
    "# Train the model\n",
    "for episode in range(num_episodes):\n",
    "    # model\n",
    "    outputs = encoder(inputs)\n",
    "    outputs = decoder(outputs)\n",
    "    \n",
    "    pairs = sampling(0,n-1,sample_qty)\n",
    "    pred,gt = bc_pairs(pairs,outputs,y)\n",
    "    loss = criterion(pred,gt)\n",
    "\n",
    "    if ~loss.requires_grad:\n",
    "        loss.requires_grad_()\n",
    "        \n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print statistics\n",
    "    print('[%d] loss: %.4f' %(episode + 1, loss.item()))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a46f25f",
   "metadata": {},
   "source": [
    "# 4. Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c05d7c",
   "metadata": {},
   "source": [
    "## 4a. Top-N% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "711a4e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topN(n,pred,gt):\n",
    "    k = math.ceil(pred.size()[0]*n/100)\n",
    "    _,pred_top = torch.topk(pred.view(-1),k=k)\n",
    "    _,gt_top = torch.topk(gt.view(-1),k=k)\n",
    "    intersect = torch.unique(torch.cat((pred_top,gt_top),0))\n",
    "    acc = (2*k-len(intersect))/k\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25009c69",
   "metadata": {},
   "source": [
    "## 4b. Kendall tau distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87be15b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kendall(pred,gt):\n",
    "    pred_ind = torch.argsort(pred)\n",
    "    gt_ind = torch.argsort(gt)\n",
    "    con = 0 # number of concordant pairs\n",
    "    dcor = 0 # number of discordant pairs\n",
    "    n = len(pred_ind)\n",
    "    for i in range(n):\n",
    "        if pred_ind[i] == gt_ind[i]:\n",
    "            con += 1\n",
    "        else:\n",
    "            dcor += 1\n",
    "    ken = 2*(con-dcor)/(n*(n-1))\n",
    "    print(ken)\n",
    "    return ken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ec74d2",
   "metadata": {},
   "source": [
    "## 4c. Wall-clock running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "771b5c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        print(f\"Running {func.__name__} ...\", end='\\r')\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"{func.__name__} Done in {end - start:.2f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7b190d",
   "metadata": {},
   "source": [
    "# 5. Putting all things together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c042e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e226e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_result(filename):\n",
    "    start_time = time.time()\n",
    "    k = [1,5,10]\n",
    "    print(\"Working on {}\".format(filename))\n",
    "    # Prepar\n",
    "    G = gList[filename]['graph']\n",
    "    y = torch.tensor([list(gList[filename]['score'].values())])\n",
    "    y = torch.transpose(y,0,1)\n",
    "\n",
    "    # Define the models\n",
    "    input_size = 3\n",
    "    hidden_size = 128\n",
    "    output_size = 1\n",
    "    num_layers = 5\n",
    "    encoder = DrBCEncoder(input_size, hidden_size, num_layers,G)\n",
    "    decoder = DrBCDecoder(hidden_size,hidden_size,output_size)\n",
    "\n",
    "    n = G.number_of_nodes()\n",
    "    num_episodes = 50\n",
    "    lr = 0.0001\n",
    "    sample_qty = 5*n\n",
    "\n",
    "    # Define the loss and optimizer\n",
    "    criterion = nn.BCELoss(reduction = 'sum')\n",
    "    optimizer = optim.Adam(list(encoder.parameters())+list(decoder.parameters()), lr=lr)\n",
    "\n",
    "    # Get the inputs\n",
    "    inputs = gen_nodes_feature(G)\n",
    "    minloss = -1\n",
    "    # Train the model\n",
    "    for episode in range(num_episodes):\n",
    "        # model\n",
    "        outputs = encoder(inputs)\n",
    "        outputs = decoder(outputs)\n",
    "\n",
    "        pairs = sampling(0,n-1,sample_qty)\n",
    "        pred,gt = bc_pairs(pairs,outputs,y)\n",
    "        loss = criterion(pred,gt)\n",
    "\n",
    "        if ~loss.requires_grad:\n",
    "            loss.requires_grad_()\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if minloss == -1:\n",
    "            minloss = loss\n",
    "            best_out = outputs\n",
    "        elif minloss>loss:\n",
    "            minloss = loss\n",
    "            best_out = outputs\n",
    "\n",
    "        # Print statistics\n",
    "        if episode%10 == 9:\n",
    "            print('[%d] loss: %.4f' %(episode + 1, loss.item()))\n",
    "    top1 = topN(1,best_out,y)\n",
    "    top5 = topN(5,best_out,y)\n",
    "    top10 = topN(10,best_out,y)\n",
    "    ken = kendall(best_out,y)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time-start_time\n",
    "    print(\"Elapsed time: {:.2f} seconds\".format(elapsed_time))\n",
    "    return top1,top5,top10,ken,elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9027c54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 0.txt\n",
      "[10] loss: 21461.6289\n",
      "[20] loss: 21363.0176\n",
      "[30] loss: 21459.9590\n",
      "[40] loss: 21446.4277\n",
      "[50] loss: 21537.6016\n",
      "0.00040008001600320064\n",
      "Elapsed time: 224.95 seconds\n",
      "Working on 1.txt\n",
      "[10] loss: 21704.9336\n",
      "[20] loss: 21955.2832\n",
      "[30] loss: 21985.9355\n",
      "[40] loss: 21990.7461\n",
      "[50] loss: 21992.7344\n",
      "0.00040008001600320064\n",
      "Elapsed time: 227.54 seconds\n",
      "Working on 10.txt\n",
      "[10] loss: 22266.9219\n",
      "[20] loss: 22193.4629\n",
      "[30] loss: 22268.7363\n",
      "[40] loss: 22274.1973\n",
      "[50] loss: 22251.7070\n",
      "0.00040008001600320064\n",
      "Elapsed time: 229.69 seconds\n",
      "Working on 11.txt\n",
      "[10] loss: 21297.0293\n",
      "[20] loss: 21292.1543\n",
      "[30] loss: 21416.5273\n",
      "[40] loss: 21322.6660\n",
      "[50] loss: 21053.7930\n",
      "0.00040008001600320064\n",
      "Elapsed time: 234.72 seconds\n",
      "Working on 12.txt\n",
      "[10] loss: 22196.8984\n",
      "[20] loss: 22130.7402\n",
      "[30] loss: 22145.6113\n",
      "[40] loss: 22242.5703\n",
      "[50] loss: 22188.6973\n",
      "0.00040008001600320064\n",
      "Elapsed time: 234.62 seconds\n",
      "Working on 13.txt\n",
      "[10] loss: 22358.1016\n",
      "[20] loss: 22336.6504\n",
      "[30] loss: 22329.0430\n",
      "[40] loss: 22457.9219\n",
      "[50] loss: 22296.4004\n",
      "0.00040008001600320064\n",
      "Elapsed time: 230.62 seconds\n",
      "Working on 14.txt\n",
      "[10] loss: 22525.6504\n",
      "[20] loss: 22473.0996\n",
      "[30] loss: 22536.8477\n",
      "[40] loss: 22416.7734\n",
      "[50] loss: 22450.9863\n",
      "0.00040008001600320064\n",
      "Elapsed time: 232.38 seconds\n",
      "Working on 15.txt\n",
      "[10] loss: 22116.8809\n",
      "[20] loss: 22048.8008\n",
      "[30] loss: 22009.0938\n",
      "[40] loss: 21935.3809\n",
      "[50] loss: 22119.5586\n",
      "0.00040008001600320064\n",
      "Elapsed time: 236.07 seconds\n",
      "Working on 16.txt\n",
      "[10] loss: 21345.4375\n",
      "[20] loss: 21583.6484\n",
      "[30] loss: 21526.5645\n",
      "[40] loss: 21471.9199\n",
      "[50] loss: 21452.6191\n",
      "0.00040008001600320064\n",
      "Elapsed time: 238.53 seconds\n",
      "Working on 17.txt\n",
      "[10] loss: 21924.4629\n",
      "[20] loss: 22066.2988\n",
      "[30] loss: 21748.3477\n",
      "[40] loss: 22155.7598\n",
      "[50] loss: 21885.8828\n",
      "0.00040008001600320064\n",
      "Elapsed time: 235.13 seconds\n",
      "Working on 18.txt\n",
      "[10] loss: 22464.3750\n",
      "[20] loss: 22506.6016\n",
      "[30] loss: 22472.4082\n",
      "[40] loss: 22431.1133\n",
      "[50] loss: 22403.5176\n",
      "0.00040008001600320064\n",
      "Elapsed time: 245.26 seconds\n",
      "Working on 19.txt\n",
      "[10] loss: 21332.7148\n",
      "[20] loss: 21197.1094\n",
      "[30] loss: 21166.8105\n",
      "[40] loss: 21318.5703\n",
      "[50] loss: 21320.9551\n",
      "0.00040008001600320064\n",
      "Elapsed time: 247.92 seconds\n",
      "Working on 2.txt\n",
      "[10] loss: 21379.1543\n",
      "[20] loss: 21468.2324\n",
      "[30] loss: 21332.3066\n",
      "[40] loss: 21366.9141\n",
      "[50] loss: 21402.3574\n",
      "0.00040008001600320064\n",
      "Elapsed time: 244.60 seconds\n",
      "Working on 20.txt\n",
      "[10] loss: 22579.6172\n",
      "[20] loss: 22466.0488\n",
      "[30] loss: 22458.6992\n",
      "[40] loss: 22553.5664\n",
      "[50] loss: 22474.4902\n",
      "0.00040008001600320064\n",
      "Elapsed time: 245.27 seconds\n",
      "Working on 21.txt\n",
      "[10] loss: 21897.0918\n",
      "[20] loss: 21911.8242\n",
      "[30] loss: 21484.9004\n",
      "[40] loss: 21796.7812\n",
      "[50] loss: 21723.8027\n",
      "0.00040008001600320064\n",
      "Elapsed time: 247.66 seconds\n",
      "Working on 22.txt\n",
      "[10] loss: 22180.6816\n",
      "[20] loss: 22129.8867\n",
      "[30] loss: 22166.3867\n",
      "[40] loss: 22188.6426\n",
      "[50] loss: 22194.8574\n",
      "0.00040008001600320064\n",
      "Elapsed time: 248.65 seconds\n",
      "Working on 23.txt\n",
      "[10] loss: 22125.6797\n",
      "[20] loss: 22152.8047\n",
      "[30] loss: 22111.3086\n",
      "[40] loss: 22136.3047\n",
      "[50] loss: 22169.4121\n",
      "0.00040008001600320064\n",
      "Elapsed time: 256.91 seconds\n",
      "Working on 24.txt\n",
      "[10] loss: 22401.2383\n",
      "[20] loss: 22318.1816\n",
      "[30] loss: 22271.6074\n",
      "[40] loss: 22384.6328\n",
      "[50] loss: 22378.6406\n",
      "0.00040008001600320064\n",
      "Elapsed time: 249.56 seconds\n",
      "Working on 25.txt\n",
      "[10] loss: 22361.7031\n",
      "[20] loss: 22354.0840\n",
      "[30] loss: 22382.2910\n",
      "[40] loss: 22432.8848\n",
      "[50] loss: 22489.8398\n",
      "0.00040008001600320064\n",
      "Elapsed time: 249.24 seconds\n",
      "Working on 26.txt\n",
      "[10] loss: 22044.7109\n",
      "[20] loss: 22007.7070\n",
      "[30] loss: 22073.1895\n",
      "[40] loss: 21986.7988\n",
      "[50] loss: 22097.4219\n",
      "0.00040008001600320064\n",
      "Elapsed time: 243.42 seconds\n",
      "Working on 27.txt\n",
      "[10] loss: 22345.2129\n",
      "[20] loss: 22250.2578\n",
      "[30] loss: 22291.8789\n",
      "[40] loss: 22290.7617\n",
      "[50] loss: 22280.7461\n",
      "0.00040008001600320064\n",
      "Elapsed time: 254.93 seconds\n",
      "Working on 28.txt\n",
      "[10] loss: 21745.4219\n",
      "[20] loss: 21903.9961\n",
      "[30] loss: 21831.6035\n",
      "[40] loss: 21668.4180\n",
      "[50] loss: 21671.5801\n",
      "0.00040008001600320064\n",
      "Elapsed time: 251.59 seconds\n",
      "Working on 29.txt\n",
      "[10] loss: 22389.7266\n",
      "[20] loss: 22390.7891\n",
      "[30] loss: 22427.9141\n",
      "[40] loss: 22394.8242\n",
      "[50] loss: 22413.9160\n",
      "0.00040008001600320064\n",
      "Elapsed time: 251.07 seconds\n",
      "Working on 3.txt\n",
      "[10] loss: 21781.8223\n",
      "[20] loss: 21617.6914\n",
      "[30] loss: 21740.4375\n",
      "[40] loss: 21686.8184\n",
      "[50] loss: 21745.7285\n",
      "0.00040008001600320064\n",
      "Elapsed time: 258.66 seconds\n",
      "Working on 4.txt\n",
      "[10] loss: 21321.9531\n",
      "[20] loss: 21351.4453\n",
      "[30] loss: 21166.9043\n",
      "[40] loss: 21368.5918\n",
      "[50] loss: 21281.6758\n",
      "0.00040008001600320064\n",
      "Elapsed time: 251.37 seconds\n",
      "Working on 5.txt\n",
      "[10] loss: 21465.8398\n",
      "[20] loss: 21775.1094\n",
      "[30] loss: 21428.6250\n",
      "[40] loss: 21592.1230\n",
      "[50] loss: 21399.2324\n",
      "0.00040008001600320064\n",
      "Elapsed time: 250.65 seconds\n",
      "Working on 6.txt\n",
      "[10] loss: 22358.6250\n",
      "[20] loss: 22332.8984\n",
      "[30] loss: 22393.3535\n",
      "[40] loss: 22422.9023\n",
      "[50] loss: 22375.4102\n",
      "0.00040008001600320064\n",
      "Elapsed time: 256.48 seconds\n",
      "Working on 7.txt\n",
      "[10] loss: 22458.7168\n",
      "[20] loss: 22447.9492\n",
      "[30] loss: 22425.3164\n",
      "[40] loss: 22414.9434\n",
      "[50] loss: 22440.1562\n",
      "0.00040008001600320064\n",
      "Elapsed time: 252.72 seconds\n",
      "Working on 8.txt\n",
      "[10] loss: 22119.3730\n",
      "[20] loss: 22205.5059\n",
      "[30] loss: 22178.8848\n",
      "[40] loss: 22119.5566\n",
      "[50] loss: 22160.5488\n",
      "0.00040008001600320064\n",
      "Elapsed time: 268.95 seconds\n",
      "Working on 9.txt\n",
      "[10] loss: 22399.3848\n",
      "[20] loss: 22374.9316\n",
      "[30] loss: 22383.0176\n",
      "[40] loss: 22350.7812\n",
      "[50] loss: 22414.9023\n",
      "0.00040008001600320064\n",
      "Elapsed time: 264.92 seconds\n"
     ]
    }
   ],
   "source": [
    "top1_list = []\n",
    "top5_list = []\n",
    "top10_list = []\n",
    "ken_list = []\n",
    "elapsed_time_list = []\n",
    "for filename in filenames[:-1]:\n",
    "    top1,top5,top10,ken,elapsed_time = train_and_result(filename)\n",
    "    top1_list.append(top1)\n",
    "    top5_list.append(top5)\n",
    "    top10_list.append(top10)\n",
    "    ken_list.append(ken)\n",
    "    elapsed_time_list.append(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "303b22f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1% accuracy: 0.31±0.32\n",
      "Top-5% accuracy: 0.23±0.23\n",
      "Top-10% accuracy: 0.21±0.18\n",
      "Kendall tau distance: 0.00±0.00\n",
      "Running time: 245.47±10.87\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean for each evaluation metrics:\n",
    "print(\"Top-1% accuracy: {:.2f}±{:.2f}\".format(np.mean(np.array(top1_list)),np.std(np.array(top1_list))))\n",
    "print(\"Top-5% accuracy: {:.2f}±{:.2f}\".format(np.mean(np.array(top5_list)),np.std(np.array(top5_list))))\n",
    "print(\"Top-10% accuracy: {:.2f}±{:.2f}\".format(np.mean(np.array(top10_list)),np.std(np.array(top10_list))))\n",
    "print(\"Kendall tau distance: {:.2f}±{:.2f}\".format(np.mean(np.array(ken_list)),np.std(np.array(ken_list))))\n",
    "print(\"Running time: {:.2f}±{:.2f}\".format(np.mean(np.array(elapsed_time_list)),np.std(np.array(elapsed_time_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bae93541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_result(filename):\n",
    "    start_time = time.time()\n",
    "    k = [1,5,10]\n",
    "    print(\"Working on {}\".format(filename))\n",
    "    # Preparing the data\n",
    "    G = gList[filename]['graph']\n",
    "    y = torch.tensor([list(gList[filename]['score'].values())])\n",
    "    y = torch.transpose(y,0,1)\n",
    "    X = gen_nodes_feature(G)\n",
    "    X_train,X_val,y_train,y_val = train_test_split(X,y,test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    # Create dataset\n",
    "    \n",
    "    print(X_train.shape,y_train.shape,X_val.shape,y_val.shape)\n",
    "    pairs_train = [(i, j) for i in range(len(y_train)) for j in range(i+1, len(y_train))]\n",
    "    train_data = My_Dataset(X_train,y_train)\n",
    "    train_loader = DataLoader(train_data,batch_size = len(train_data), shuffle=True)\n",
    "    \n",
    "    pairs_val = [(i, j) for i in range(len(y_val)) for j in range(i+1, len(y_val))]\n",
    "    val_data = My_Dataset(X_val,y_val)\n",
    "    val_loader = DataLoader(val_data,batch_size = len(val_data), shuffle=True)\n",
    "    \n",
    "    \n",
    "    # Define the models\n",
    "    input_size = 3\n",
    "    hidden_size = 128\n",
    "    output_size = 1\n",
    "    num_layers = 5\n",
    "    encoder = DrBCEncoder(input_size, hidden_size, num_layers,G)\n",
    "    decoder = DrBCDecoder(hidden_size,hidden_size,output_size)\n",
    "    model = EncoderDecoder(encoder,decoder)\n",
    "    \n",
    "    epochs = 50 # num of episodes\n",
    "    lr = 0.0001\n",
    "\n",
    "    # Define the loss and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction = 'sum')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Train the model\n",
    "    best_loss = float('inf')\n",
    "    best_model_weights = None\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X, y in train_loader:\n",
    "            print(X.shape,y.shape)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            pred, gt = bc_pairs(pairs_train, outputs, y)\n",
    "            loss = criterion(pred, gt)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Print the training loss every 10 epochs\n",
    "        if epoch% 10 == 9:\n",
    "            print(\"Epoch {}: Loss = {:.4f}\".format(epoch+1, loss.item()))\n",
    "            \n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for X, y in val_loader:\n",
    "                X = X.squeeze(dim=0)\n",
    "                y = y.squeeze(dim=0)\n",
    "                outputs = model(X)\n",
    "                pred, gt = bc_pairs(pairs_val, outputs, y)\n",
    "                loss = criterion(pred, gt)\n",
    "        \n",
    "        # Print the validation loss every 10 epochs\n",
    "        if epoch% 10 == 9:\n",
    "            print(\"Epoch {}: Loss = {:.4f}\".format(epoch+1, loss.item()))\n",
    "            \n",
    "        if minloss>loss.item():\n",
    "            best_loss = loss.item()\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            \n",
    "    saved_params = torch.load(\"best_model.pth\")\n",
    "    model.load_state_dict(saved_params)\n",
    "    model.eval()\n",
    "    best_out = model(X)\n",
    "    \n",
    "    \n",
    "    top1 = topN(1,best_out,y)\n",
    "    top5 = topN(5,best_out,y)\n",
    "    top10 = topN(10,best_out,y)\n",
    "    ken = kendall(best_out,y)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time-start_time\n",
    "    print(\"Elapsed time: {:.2f} seconds\".format(elapsed_time))\n",
    "    return top1,top5,top10,ken,elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59c49ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 0.txt\n",
      "torch.Size([4000, 3]) torch.Size([4000, 1]) torch.Size([1000, 3]) torch.Size([1000, 1])\n",
      "torch.Size([1, 3]) torch.Size([1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\caleb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 128])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2116\\2731718071.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_and_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2116\\2209882906.py\u001b[0m in \u001b[0;36mtrain_and_result\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbc_pairs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairs_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2116\\3854665434.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2116\\4231332408.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         )\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2446\u001b[0m         )\n\u001b[0;32m   2447\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2448\u001b[1;33m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2450\u001b[0m     return torch.batch_norm(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m   2414\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2415\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2416\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 128])"
     ]
    }
   ],
   "source": [
    "train_and_result('0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a191b05f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
